{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Crystalline Checkpoint\n",
    "\n",
    "Interactive exploration of a trained Crystalline model checkpoint.\n",
    "\n",
    "This notebook allows you to:\n",
    "- Load and inspect checkpoint metadata\n",
    "- Visualize bottleneck statistics (temperatures, codebook)\n",
    "- Run inference and analyze code activations\n",
    "- Generate interactive plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup path for imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent.parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from analysis import (\n",
    "    load_checkpoint_for_analysis,\n",
    "    extract_bottleneck_stats,\n",
    "    setup_style,\n",
    "    COLORS,\n",
    ")\n",
    "\n",
    "# Try to import interactive visualizations\n",
    "try:\n",
    "    from analysis.visualize_interactive import (\n",
    "        plot_layer_temperatures_interactive,\n",
    "        plot_codebook_usage_interactive,\n",
    "    )\n",
    "    INTERACTIVE = True\n",
    "    print(\"Interactive visualizations available (Plotly)\")\n",
    "except ImportError:\n",
    "    INTERACTIVE = False\n",
    "    print(\"Plotly not available - using static plots\")\n",
    "    from analysis.visualize import plot_layer_temperatures, plot_codebook_usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify checkpoint path\n",
    "CHECKPOINT_PATH = project_root / \"checkpoints\" / \"tinystories\" / \"checkpoint_final.pt\"\n",
    "\n",
    "# Alternative: specify your own path\n",
    "# CHECKPOINT_PATH = Path(\"/path/to/your/checkpoint.pt\")\n",
    "\n",
    "print(f\"Loading checkpoint: {CHECKPOINT_PATH}\")\n",
    "print(f\"Exists: {CHECKPOINT_PATH.exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load checkpoint\n",
    "if CHECKPOINT_PATH.exists():\n",
    "    result = load_checkpoint_for_analysis(CHECKPOINT_PATH)\n",
    "    print(\"Checkpoint loaded successfully!\")\n",
    "else:\n",
    "    print(\"Checkpoint not found. Run training first or specify a different path.\")\n",
    "    result = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Checkpoint Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if result:\n",
    "    print(\"=\" * 50)\n",
    "    print(\"CHECKPOINT METADATA\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Training Step: {result.step}\")\n",
    "    print(f\"Epoch: {result.epoch}\")\n",
    "    print(f\"\\nModel Config:\")\n",
    "    for key, value in result.config.get('model', {}).items():\n",
    "        if key != 'bottleneck':\n",
    "            print(f\"  {key}: {value}\")\n",
    "    print(f\"\\nBottleneck Config:\")\n",
    "    for key, value in result.config.get('model', {}).get('bottleneck', {}).items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    print(f\"\\nSaved Metrics:\")\n",
    "    for key, value in result.metrics.items():\n",
    "        if isinstance(value, float):\n",
    "            print(f\"  {key}: {value:.4f}\")\n",
    "        else:\n",
    "            print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Bottleneck Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if result:\n",
    "    stats = result.bottleneck_stats\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(\"BOTTLENECK STATISTICS\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Number of layers: {stats['n_layers']}\")\n",
    "    print(f\"Codebook size: {stats['codebook_sizes'][0]}\")\n",
    "    print(f\"Top-k codes: {stats['num_codes_k'][0]}\")\n",
    "    print(f\"\\nTemperature Summary:\")\n",
    "    print(f\"  Mean: {stats['temperature_summary']['mean']:.4f}\")\n",
    "    print(f\"  Min:  {stats['temperature_summary']['min']:.4f}\")\n",
    "    print(f\"  Max:  {stats['temperature_summary']['max']:.4f}\")\n",
    "    print(f\"  Std:  {stats['temperature_summary']['std']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if result:\n",
    "    print(\"\\nPer-Layer Temperatures:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"{'Layer':<8} {'Attention':<12} {'MLP':<12}\")\n",
    "    print(\"-\" * 40)\n",
    "    for layer_stats in stats['layers']:\n",
    "        i = layer_stats['layer']\n",
    "        attn_t = layer_stats['attn']['temperature']\n",
    "        mlp_t = layer_stats['mlp']['temperature']\n",
    "        print(f\"L{i:<7} {attn_t:<12.4f} {mlp_t:<12.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize Temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if result:\n",
    "    temps = stats['temperatures']\n",
    "    \n",
    "    if INTERACTIVE:\n",
    "        fig = plot_layer_temperatures_interactive(temps)\n",
    "        fig.show()\n",
    "    else:\n",
    "        setup_style('notebook')\n",
    "        fig = plot_layer_temperatures(temps)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if result:\n",
    "    model = result.model\n",
    "    \n",
    "    # Count parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(\"MODEL SUMMARY\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "    print(f\"\\nModel architecture:\")\n",
    "    print(f\"  Vocab size: {model.token_embedding.num_embeddings}\")\n",
    "    print(f\"  Hidden dim: {model.token_embedding.embedding_dim}\")\n",
    "    print(f\"  Layers: {len(model.blocks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Codebook Analysis\n",
    "\n",
    "Analyze the learned codebook vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if result:\n",
    "    from analysis.checkpoint_analysis import get_codebook_embeddings\n",
    "    \n",
    "    # Get codebook from first layer's attention bottleneck\n",
    "    codebook = get_codebook_embeddings(result.model, layer=0, bn_type='attn')\n",
    "    \n",
    "    print(f\"Codebook shape: {codebook.shape}\")\n",
    "    print(f\"Codebook norm (should be ~1 for normalized): {np.linalg.norm(codebook, axis=1).mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if result:\n",
    "    # Compute pairwise similarities\n",
    "    codebook_norm = codebook / np.linalg.norm(codebook, axis=1, keepdims=True)\n",
    "    similarities = codebook_norm @ codebook_norm.T\n",
    "    \n",
    "    # Visualize similarity matrix\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    setup_style('notebook')\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    im = ax.imshow(similarities, cmap='RdBu_r', vmin=-1, vmax=1)\n",
    "    ax.set_xlabel('Code Index')\n",
    "    ax.set_ylabel('Code Index')\n",
    "    ax.set_title('Codebook Similarity Matrix (Layer 0, Attention)')\n",
    "    plt.colorbar(im, ax=ax, label='Cosine Similarity')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Statistics\n",
    "    off_diag = similarities[np.triu_indices(len(similarities), k=1)]\n",
    "    print(f\"\\nOff-diagonal similarity stats:\")\n",
    "    print(f\"  Mean: {off_diag.mean():.4f}\")\n",
    "    print(f\"  Std:  {off_diag.std():.4f}\")\n",
    "    print(f\"  Max:  {off_diag.max():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Run Inference (Optional)\n",
    "\n",
    "Run the model on sample data to collect code activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample input\n",
    "if result:\n",
    "    vocab_size = model.token_embedding.num_embeddings\n",
    "    \n",
    "    # Random tokens as example\n",
    "    sample_input = torch.randint(0, vocab_size, (1, 32))\n",
    "    print(f\"Sample input shape: {sample_input.shape}\")\n",
    "    \n",
    "    # Run inference\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits, infos = model(sample_input)\n",
    "    \n",
    "    print(f\"Output logits shape: {logits.shape}\")\n",
    "    print(f\"Number of layer infos: {len(infos)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze code activations from inference\n",
    "if result and 'infos' in dir():\n",
    "    print(\"\\nCode Activation Statistics (per layer):\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"{'Layer':<8} {'Type':<8} {'Entropy':<12} {'Active Codes':<15}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for layer_info in infos:\n",
    "        layer_idx = layer_info['layer']\n",
    "        for bn_type in ['attn', 'mlp']:\n",
    "            info = layer_info[bn_type]\n",
    "            entropy = info['entropy'].item()\n",
    "            hard_codes = info['hard_codes']\n",
    "            active = (hard_codes > 0.5).sum().item()\n",
    "            total = hard_codes.numel()\n",
    "            print(f\"L{layer_idx:<7} {bn_type:<8} {entropy:<12.4f} {active}/{total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Analysis\n",
    "\n",
    "Export analysis results for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if result:\n",
    "    import json\n",
    "    \n",
    "    # Create analysis summary\n",
    "    analysis_summary = {\n",
    "        'checkpoint_path': str(CHECKPOINT_PATH),\n",
    "        'step': result.step,\n",
    "        'epoch': result.epoch,\n",
    "        'temperature_summary': stats['temperature_summary'],\n",
    "        'temperatures_per_layer': {\n",
    "            'attn': stats['temperatures']['attn'],\n",
    "            'mlp': stats['temperatures']['mlp'],\n",
    "        },\n",
    "        'n_layers': stats['n_layers'],\n",
    "        'codebook_size': stats['codebook_sizes'][0],\n",
    "    }\n",
    "    \n",
    "    # Save to JSON\n",
    "    output_path = project_root / 'analysis_output.json'\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(analysis_summary, f, indent=2)\n",
    "    \n",
    "    print(f\"Analysis saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- **FSM Analysis**: See `fsm_analysis.ipynb` for state-code alignment analysis\n",
    "- **TinyStories Analysis**: See `tinystories_analysis.ipynb` for language model analysis\n",
    "- **Generate Figures**: Use `analysis.visualize` to create publication-quality plots"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
